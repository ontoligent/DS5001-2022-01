{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai-gvPnADykO",
    "toc-hr-collapsed": true
   },
   "source": [
    "# DS 5001 Week 3 Lab: Inferring Language Models\n",
    "\n",
    "We now create a series of langage models and evaluate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5x8B8RODykY",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fb3ZsuIsDykn"
   },
   "outputs": [],
   "source": [
    "data_in = \"./data_in\"\n",
    "data_out = './data_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fb3ZsuIsDykn"
   },
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "text_file1 = data_in + '/austen-persuasion.csv'\n",
    "text_file2 = data_in + '/austen-sense.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and combine texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = pd.read_csv(text_file1)\n",
    "text2 = pd.read_csv(text_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Kellynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Somersetshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chap_num  para_num  sent_num  token_num      token_str\n",
       "0         1         1         0          0            Sir\n",
       "1         1         1         0          1         Walter\n",
       "2         1         1         0          2         Elliot\n",
       "3         1         1         0          3             of\n",
       "4         1         1         0          4       Kellynch\n",
       "5         1         1         0          5           Hall\n",
       "6         1         1         0          6             in\n",
       "7         1         1         0          7  Somersetshire\n",
       "8         1         1         0          8            was\n",
       "9         1         1         0          9              a"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1['book_id'] = 1\n",
    "text2['book_id'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th>token_str</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Elliot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Kellynch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chap_num  para_num  sent_num  token_num token_str  book_id\n",
       "0         1         1         0          0       Sir        1\n",
       "1         1         1         0          1    Walter        1\n",
       "2         1         1         0          2    Elliot        1\n",
       "3         1         1         0          3        of        1\n",
       "4         1         1         0          4  Kellynch        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.concat([text1, text2]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens.set_index(OHCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kellynch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             token_str\n",
       "book_id chap_num para_num sent_num token_num          \n",
       "1       1        1        0        0               Sir\n",
       "                                   1            Walter\n",
       "                                   2            Elliot\n",
       "                                   3                of\n",
       "                                   4          Kellynch"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['term_str'] = tokens['token_str'].str.lower().str.replace(r'[\\W_]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Sir</td>\n",
       "      <td>sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walter</td>\n",
       "      <td>walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elliot</td>\n",
       "      <td>elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kellynch</td>\n",
       "      <td>kellynch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             token_str  term_str\n",
       "book_id chap_num para_num sent_num token_num                    \n",
       "1       1        1        0        0               Sir       sir\n",
       "                                   1            Walter    walter\n",
       "                                   2            Elliot    elliot\n",
       "                                   3                of        of\n",
       "                                   4          Kellynch  kellynch"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokens['term_str'].value_counts()\\\n",
    "    .to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'term_str':'n', 'index':'term_str'})\\\n",
    "    .sort_values('term_str')\n",
    "vocab.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td></td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>1760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str   n\n",
       "term_id             \n",
       "758               29\n",
       "3631           1   3\n",
       "5949          15   1\n",
       "6997          16   1\n",
       "8028        1760   1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>holds</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>enjoyment</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>nursery</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>slighter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7037</th>\n",
       "      <td>perpetually</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            term_str   n\n",
       "term_id                 \n",
       "3168           holds   4\n",
       "681        enjoyment  33\n",
       "2505         nursery   6\n",
       "8104        slighter   1\n",
       "7037     perpetually   1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Unigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Term probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = vocab.n.sum()\n",
    "vocab['p'] = vocab['n'] / n_tokens\n",
    "vocab['i'] = np.log2(1/vocab['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204833"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Entropy and of the Vocabulary\n",
    "\n",
    "Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_terms = vocab.shape[0]\n",
    "H = (vocab.p * vocab.i).sum()\n",
    "Hmax = np.log2(n_terms)\n",
    "R = 1 - (H/Hmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2965421207433586"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the redundancy of Austen's English from these two novels $R_{austen}$ is about $30\\%$. Shannon estimated the redundancy of English $R_{english}$ to be $54\\%$ (see Shannon 1953 in the Readings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>7436</td>\n",
       "      <td>0.036303</td>\n",
       "      <td>4.783778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>6924</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>4.886699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>6290</td>\n",
       "      <td>0.030708</td>\n",
       "      <td>5.025244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>6145</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>5.058891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>her</td>\n",
       "      <td>3747</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>5.772568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>3687</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>5.795857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>3368</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>5.926412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>was</td>\n",
       "      <td>3198</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>6.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>3128</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>6.033064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.013645</td>\n",
       "      <td>6.195456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str     n         p         i\n",
       "term_id                                   \n",
       "0            the  7436  0.036303  4.783778\n",
       "1             to  6924  0.033803  4.886699\n",
       "2            and  6290  0.030708  5.025244\n",
       "3             of  6145  0.030000  5.058891\n",
       "4            her  3747  0.018293  5.772568\n",
       "5              a  3687  0.018000  5.795857\n",
       "6             in  3368  0.016443  5.926412\n",
       "7            was  3198  0.015613  6.001134\n",
       "8              i  3128  0.015271  6.033064\n",
       "9             it  2795  0.013645  6.195456"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.sort_values('p', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "text",
    "id": "NfMtOiCYDylX",
    "toc-hr-collapsed": false
   },
   "outputs": [],
   "source": [
    "smooth = vocab['p'].min()\n",
    "def predict_sentence(sent_str):\n",
    "    \n",
    "    # Parse sentence into tokens and normalize string\n",
    "    tokens = pd.DataFrame(sent_str.lower().split(), columns=['term_str'])\n",
    "    \n",
    "    # Link the tokens with model vocabulary\n",
    "    tokens = tokens.merge(vocab, on='term_str', how='left') # Left join is key\n",
    "    \n",
    "    # Add minimum values where token is not in our vocabulary\n",
    "    tokens.loc[tokens['p'].isna(), 'p'] = [smooth]\n",
    "    \n",
    "    # Compute probability of sentence by getting product of token probabilities\n",
    "    p = tokens['p'].product()\n",
    "        \n",
    "    # Print results\n",
    "    print(\"p('{}') = {}\".format(sent_str, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "text",
    "id": "NfMtOiCYDylX",
    "toc-hr-collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p('I love you') = 7.878556023336425e-08\n",
      "p('I love cars') = 4.3312567472987495e-11\n",
      "p('I want to') = 1.8649008463478524e-07\n",
      "p('anne said to') = 2.3099369325723746e-07\n",
      "p('said to her') = 1.7207422835683278e-06\n",
      "p('said to him') = 5.092882819528357e-07\n"
     ]
    }
   ],
   "source": [
    "predict_sentence('I love you')\n",
    "predict_sentence('I love cars')\n",
    "predict_sentence(\"I want to\")\n",
    "predict_sentence(\"anne said to\")\n",
    "predict_sentence(\"said to her\")\n",
    "predict_sentence('said to him')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfMtOiCYDylX",
    "toc-hr-collapsed": true
   },
   "source": [
    "## N-Gram models\n",
    "\n",
    "This function generates models up to the length specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPUTfjSDDylz"
   },
   "outputs": [],
   "source": [
    "def get_ngrams(tokens, n=2):\n",
    "    \n",
    "    global OHCO\n",
    "    \n",
    "    # Create list to store copies of tokens table\n",
    "    X = []\n",
    "    \n",
    "    # Convert the index to cols in order to change the value of token_num\n",
    "    X.append(tokens['term_str'].reset_index())\n",
    "        \n",
    "    # Create copies of token table for each level of ngram, offset by 1, and \n",
    "    # merge with previous \n",
    "    for i in range(1, n):\n",
    "        X.append(X[0].copy())\n",
    "        X[i]['token_num'] = X[i]['token_num'] + i\n",
    "        X[i] = X[i].merge(X[i-1], on=OHCO, how='left', sort=True).fillna('<s>')\n",
    "        \n",
    "    # Compress tables to unique ngrams with counts\n",
    "    for i in range(0, n):\n",
    "        X[i] = X[i].drop(OHCO, 1)\n",
    "        cols = X[i].columns.tolist()\n",
    "        X[i]['n'] = 0\n",
    "        X[i] = X[i].groupby(cols).n.apply(lambda x: x.count()).to_frame()\n",
    "        X[i].index.names = ['w{}'.format(j) for j in range(i+1)]\n",
    "            \n",
    "    # Return just the ngram tables\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "source": [
    "### Generate three models\n",
    "\n",
    "Unigram, bigram, and trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "outputs": [],
   "source": [
    "m1, m2, m3 = get_ngrams(tokens, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "outputs": [],
   "source": [
    "# m3.sort_values('n', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute joint probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "outputs": [],
   "source": [
    "m1['p'] = m1['n'] / m1['n'].sum()\n",
    "m2['p'] = m2['n'] / m2['n'].sum()\n",
    "m3['p'] = m3['n'] / m3['n'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>7436</td>\n",
       "      <td>0.036303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>6924</td>\n",
       "      <td>0.033803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>6290</td>\n",
       "      <td>0.030708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>6145</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>3747</td>\n",
       "      <td>0.018293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n         p\n",
       "w0                 \n",
       "the  7436  0.036303\n",
       "to   6924  0.033803\n",
       "and  6290  0.030708\n",
       "of   6145  0.030000\n",
       "her  3747  0.018293"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.sort_values('p', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <td>857</td>\n",
       "      <td>0.004184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <td>814</td>\n",
       "      <td>0.003974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <th>the</th>\n",
       "      <td>683</td>\n",
       "      <td>0.003334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrs</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>530</td>\n",
       "      <td>0.002587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <th>was</th>\n",
       "      <td>498</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n         p\n",
       "w0  w1                \n",
       "of  the  857  0.004184\n",
       "to  be   814  0.003974\n",
       "in  the  683  0.003334\n",
       "mrs <s>  530  0.002587\n",
       "it  was  498  0.002431"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.sort_values('p', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mrs</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>530</td>\n",
       "      <td>0.002587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>369</td>\n",
       "      <td>0.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>244</td>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>229</td>\n",
       "      <td>0.001118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>179</td>\n",
       "      <td>0.000874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>172</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>163</td>\n",
       "      <td>0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>162</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elinor</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>119</td>\n",
       "      <td>0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>am</th>\n",
       "      <th>sure</th>\n",
       "      <td>107</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <th>could</th>\n",
       "      <th>not</th>\n",
       "      <td>93</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marianne</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>90</td>\n",
       "      <td>0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>again</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>85</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <th>soon</th>\n",
       "      <th>as</th>\n",
       "      <td>82</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>82</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       n         p\n",
       "w0       w1    w2                 \n",
       "mrs      <s>   <s>   530  0.002587\n",
       "it       <s>   <s>   369  0.001801\n",
       "her      <s>   <s>   244  0.001191\n",
       "him      <s>   <s>   229  0.001118\n",
       "mr       <s>   <s>   179  0.000874\n",
       "you      <s>   <s>   172  0.000840\n",
       "them     <s>   <s>   163  0.000796\n",
       "me       <s>   <s>   162  0.000791\n",
       "elinor   <s>   <s>   119  0.000581\n",
       "i        am    sure  107  0.000522\n",
       "she      could not    93  0.000454\n",
       "marianne <s>   <s>    90  0.000439\n",
       "again    <s>   <s>    85  0.000415\n",
       "as       soon  as     82  0.000400\n",
       "all      <s>   <s>    82  0.000400"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.sort_values('p', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute conditional probabilities\n",
    "\n",
    "$p(w_1|w_0) = p(w_0, w_1) / p(w_0)$\n",
    "\n",
    "$p(w_2|w_0,w_1) = p(w_0, w_1, w_2) / p(w_0, w_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2x = m2.groupby('w0')[['n']].apply(lambda x: x.n.sum())\n",
    "m3x = m3.groupby(['w0','w1'])[['n']].apply(lambda x: x.n.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2m = (m2.n / m2x).to_frame('p').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3m = (m3.n / m3x).sort_values().to_frame('p').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are inefficient and produce huge files\n",
    "# m2m = m2.n.unstack().fillna(0).apply(lambda x: x / x.sum(), 1)\n",
    "# m3m = m3.n.unstack().fillna(0).apply(lambda x: x / x.sum(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence2(sent_str, n=2):\n",
    "    \n",
    "    # Pick appropriate model\n",
    "    global m1, m2, m3\n",
    "    if n == 1:\n",
    "        M = m1\n",
    "    elif n == 2:\n",
    "        M = m2\n",
    "    elif n == 3:\n",
    "        M = m3\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    # Get smoothing \n",
    "    smooth = M.p.min()\n",
    "    \n",
    "    # Add sentence padding (Hacky)\n",
    "    padded_sent_str = sent_str + (' <s>' * (n-1))\n",
    "    \n",
    "    # Parse sentence into tokens and normalize string\n",
    "    tokens = pd.DataFrame(padded_sent_str.lower().split(), columns=['term_str'])\n",
    "    \n",
    "    # Generate ngram keys \n",
    "    ngrams = []\n",
    "    offset = n - 1\n",
    "    for i in range(offset, tokens.shape[0]):\n",
    "        ngram = []\n",
    "        w = tokens.iloc[i].term_str\n",
    "        for j in range(n):\n",
    "            ngram.append(tokens.iloc[i-j].term_str)\n",
    "        ngram.reverse()\n",
    "        ngrams.append(ngram)\n",
    "        \n",
    "    # Compute the probability of the sentence\n",
    "    L = 0\n",
    "    for ngram in ngrams:\n",
    "        try:\n",
    "            p_ngram = M.loc[tuple(ngram)].p\n",
    "        except KeyError:\n",
    "            p_ngram = smooth\n",
    "        L += np.log2(p_ngram)\n",
    "    P = np.exp(L)\n",
    "    \n",
    "    print(sent_str, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you 5.645972739472476e-11\n",
      "I love cars 1.118907816687782e-15\n",
      "I want to 1.9570792682414204e-10\n",
      "anne said to 2.6650097828995353e-10\n",
      "said to her 4.829429322644128e-09\n",
      "said to him 8.338111808245719e-10\n"
     ]
    }
   ],
   "source": [
    "predict_sentence2('I love you', 1)\n",
    "predict_sentence2('I love cars', 1)\n",
    "predict_sentence2(\"I want to\", 1)\n",
    "predict_sentence2(\"anne said to\", 1)\n",
    "predict_sentence2(\"said to her\", 1)\n",
    "predict_sentence2('said to him', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you 1.6912924832811006e-18\n",
      "I love cars 2.0639180372517065e-22\n",
      "I want to 2.0994247126049545e-19\n",
      "anne said to 7.112019880991409e-20\n",
      "said to her 7.131778675619001e-15\n",
      "said to him 1.2983543385819788e-15\n"
     ]
    }
   ],
   "source": [
    "predict_sentence2('I love you', 2)\n",
    "predict_sentence2('I love cars', 2)\n",
    "predict_sentence2(\"I want to\", 2)\n",
    "predict_sentence2(\"anne said to\", 2)\n",
    "predict_sentence2(\"said to her\", 2)\n",
    "predict_sentence2('said to him', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you 1.725817247418853e-20\n",
      "I love cars 1.0275642842631827e-23\n",
      "I want to 2.0994247126049545e-19\n",
      "anne said to 1.1935219350244338e-21\n",
      "said to her 6.065124721977218e-18\n",
      "said to him 9.586541118024097e-18\n"
     ]
    }
   ],
   "source": [
    "predict_sentence2('I love you', 3)\n",
    "predict_sentence2('I love cars', 3)\n",
    "predict_sentence2(\"I want to\", 2)\n",
    "predict_sentence2(\"anne said to\", 3)\n",
    "predict_sentence2(\"said to her\", 3)\n",
    "predict_sentence2('said to him', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_pairs(list1, list2):\n",
    "    global m2m\n",
    "    test_pairs = []\n",
    "    for x in list1:\n",
    "        for y in list2:\n",
    "            pair = (x, y)\n",
    "            try:\n",
    "                m2m.loc[pair]\n",
    "                test_pairs.append((x, y))\n",
    "            except:\n",
    "                pass\n",
    "    return m2m.loc[test_pairs].unstack(fill_value=0).style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col0{\n",
       "            background-color:  #53b466;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col1{\n",
       "            background-color:  #004e1f;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col2{\n",
       "            background-color:  #98d594;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col3,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col6,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col7,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col1,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col4,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col5,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col8,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col0,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col2{\n",
       "            background-color:  #00441b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col4{\n",
       "            background-color:  #bbe4b4;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col5{\n",
       "            background-color:  #76c578;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col8{\n",
       "            background-color:  #aedea7;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col0{\n",
       "            background-color:  #cfecc9;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col2,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col7{\n",
       "            background-color:  #60ba6c;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col3{\n",
       "            background-color:  #3ea75a;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col6{\n",
       "            background-color:  #58b668;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col7{\n",
       "            background-color:  #3fa85b;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col1,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col6,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col7,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col8,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col0,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col2,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col3,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col4,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col5{\n",
       "            background-color:  #f7fcf5;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col3{\n",
       "            background-color:  #e5f5e0;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col4{\n",
       "            background-color:  #f4fbf2;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col5{\n",
       "            background-color:  #f2faef;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col1{\n",
       "            background-color:  #91d28e;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col2{\n",
       "            background-color:  #edf8e9;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col3{\n",
       "            background-color:  #8dd08a;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col4{\n",
       "            background-color:  #00481d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col5{\n",
       "            background-color:  #95d391;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col6{\n",
       "            background-color:  #d4eece;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col7,#T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col0{\n",
       "            background-color:  #e8f6e4;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col8{\n",
       "            background-color:  #a2d99c;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col1{\n",
       "            background-color:  #e7f6e3;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col6{\n",
       "            background-color:  #70c274;\n",
       "            color:  #000000;\n",
       "        }#T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col8{\n",
       "            background-color:  #bce4b5;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" colspan=9>p</th>    </tr>    <tr>        <th class=\"index_name level1\" >w1</th>        <th class=\"col_heading level1 col0\" >is</th>        <th class=\"col_heading level1 col1\" >had</th>        <th class=\"col_heading level1 col2\" >was</th>        <th class=\"col_heading level1 col3\" >did</th>        <th class=\"col_heading level1 col4\" >felt</th>        <th class=\"col_heading level1 col5\" >thought</th>        <th class=\"col_heading level1 col6\" >looked</th>        <th class=\"col_heading level1 col7\" >said</th>        <th class=\"col_heading level1 col8\" >saw</th>    </tr>    <tr>        <th class=\"index_name level0\" >w0</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122level0_row0\" class=\"row_heading level0 row0\" >he</th>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col0\" class=\"data row0 col0\" >0.057803</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col1\" class=\"data row0 col1\" >0.144990</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col2\" class=\"data row0 col2\" >0.120906</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col3\" class=\"data row0 col3\" >0.030829</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col4\" class=\"data row0 col4\" >0.005299</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col5\" class=\"data row0 col5\" >0.004817</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col6\" class=\"data row0 col6\" >0.008671</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col7\" class=\"data row0 col7\" >0.016378</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row0_col8\" class=\"data row0 col8\" >0.005299</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122level0_row1\" class=\"row_heading level0 row1\" >she</th>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col0\" class=\"data row1 col0\" >0.024284</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col1\" class=\"data row1 col1\" >0.148967</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col2\" class=\"data row1 col2\" >0.135194</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col3\" class=\"data row1 col3\" >0.021385</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col4\" class=\"data row1 col4\" >0.018123</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col5\" class=\"data row1 col5\" >0.009786</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col6\" class=\"data row1 col6\" >0.005074</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col7\" class=\"data row1 col7\" >0.010511</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row1_col8\" class=\"data row1 col8\" >0.015948</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122level0_row2\" class=\"row_heading level0 row2\" >it</th>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col0\" class=\"data row2 col0\" >0.096959</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col1\" class=\"data row2 col1\" >0.022540</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col2\" class=\"data row2 col2\" >0.178175</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col3\" class=\"data row2 col3\" >0.007871</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col4\" class=\"data row2 col4\" >0.000358</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col5\" class=\"data row2 col5\" >0.000358</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col6\" class=\"data row2 col6\" >0.000358</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col7\" class=\"data row2 col7\" >0.000358</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row2_col8\" class=\"data row2 col8\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122level0_row3\" class=\"row_heading level0 row3\" >anne</th>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col0\" class=\"data row3 col0\" >0.003976</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col1\" class=\"data row3 col1\" >0.075547</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col2\" class=\"data row3 col2\" >0.089463</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col3\" class=\"data row3 col3\" >0.015905</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col4\" class=\"data row3 col4\" >0.017893</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col5\" class=\"data row3 col5\" >0.003976</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col6\" class=\"data row3 col6\" >0.001988</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col7\" class=\"data row3 col7\" >0.001988</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row3_col8\" class=\"data row3 col8\" >0.005964</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122level0_row4\" class=\"row_heading level0 row4\" >wentworth</th>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col0\" class=\"data row4 col0\" >0.013761</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col1\" class=\"data row4 col1\" >0.036697</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col2\" class=\"data row4 col2\" >0.082569</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col3\" class=\"data row4 col3\" >0.004587</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col5\" class=\"data row4 col5\" >0.000000</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col6\" class=\"data row4 col6\" >0.004587</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col7\" class=\"data row4 col7\" >0.009174</td>\n",
       "                        <td id=\"T_fbec0b48_6e72_11eb_9fc5_acde48001122row4_col8\" class=\"data row4 col8\" >0.004587</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa260332e50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_pairs(['he','she','it','anne','wentworth'], ['is','had','was','did','felt','thought','looked','said','saw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_fbf1b80e_6e72_11eb_9fc5_acde48001122row0_col0,#T_fbf1b80e_6e72_11eb_9fc5_acde48001122row1_col1{\n",
       "            background-color:  #00441b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_fbf1b80e_6e72_11eb_9fc5_acde48001122row0_col1{\n",
       "            background-color:  #bee5b8;\n",
       "            color:  #000000;\n",
       "        }#T_fbf1b80e_6e72_11eb_9fc5_acde48001122row1_col0{\n",
       "            background-color:  #3fa85b;\n",
       "            color:  #000000;\n",
       "        }#T_fbf1b80e_6e72_11eb_9fc5_acde48001122row2_col0,#T_fbf1b80e_6e72_11eb_9fc5_acde48001122row2_col1{\n",
       "            background-color:  #f7fcf5;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" colspan=2>p</th>    </tr>    <tr>        <th class=\"index_name level1\" >w1</th>        <th class=\"col_heading level1 col0\" >said</th>        <th class=\"col_heading level1 col1\" >felt</th>    </tr>    <tr>        <th class=\"index_name level0\" >w0</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122level0_row0\" class=\"row_heading level0 row0\" >he</th>\n",
       "                        <td id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122row0_col0\" class=\"data row0 col0\" >0.016378</td>\n",
       "                        <td id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122row0_col1\" class=\"data row0 col1\" >0.005299</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122level0_row1\" class=\"row_heading level0 row1\" >she</th>\n",
       "                        <td id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122row1_col0\" class=\"data row1 col0\" >0.010511</td>\n",
       "                        <td id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122row1_col1\" class=\"data row1 col1\" >0.018123</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122level0_row2\" class=\"row_heading level0 row2\" >it</th>\n",
       "                        <td id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122row2_col0\" class=\"data row2 col0\" >0.000358</td>\n",
       "                        <td id=\"T_fbf1b80e_6e72_11eb_9fc5_acde48001122row2_col1\" class=\"data row2 col1\" >0.000358</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa25eafc790>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_pairs(['he', 'she', 'it'], ['said','felt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPY7ekfXgbE_"
   },
   "source": [
    "## Generate Text\n",
    "\n",
    "We use back-off to account for missing ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(start_word='she', n=250):\n",
    "    words = [start_word]\n",
    "    for i in range(n):\n",
    "        if len(words) == 1:\n",
    "            w = m2m.loc[start_word].p\n",
    "            next_word = m2m.loc[start_word].sample(weights=w).index.values[0]\n",
    "        elif len(words) > 1:\n",
    "            bg = tuple(words[-2:])\n",
    "            try:\n",
    "                w = m3m.loc[bg].p\n",
    "                next_word = m3m.loc[bg].sample(weights=w).index.values[0]\n",
    "            except KeyError:\n",
    "                ug = bg[1]\n",
    "                if ug == '<s>':\n",
    "                    next_word = m1.sample(weights=m1.p).index[0]\n",
    "                else:\n",
    "                    w = m2m.loc[ug].p\n",
    "                    next_word = m2m.loc[ug].sample(weights=w).index.values[0]\n",
    "        words.append(next_word)\n",
    "    text = ' '.join(words)\n",
    "    text = text.replace(' <s> <s>', '.') + '.'\n",
    "    text = text.upper() # To give that telegraph message look :-)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE STREIGHTS AND NEVER WAS. KNEW. FULL SENSATION CHARLES MARY ANNE HENRIETTA LOUISA AND NOT VERY NEAR. AND MRS. WITH HER SISTER S ENTREATIES AND PROMISE TO HIS LARGE FISHING NET AT ONE TIME ATTACHED TO WOMAN THAN POOR BENWICK HAD BEEN IN MY BEING ACQUAINTED WITH THE SIZE AND MENTAL ALACRITY DID NOT QUITE UNCONNECTED IN THIS PART OF ENGLAND ACCOMPANYING HER HUSBAND. ADMIRE HER MORE COMFORTABLE AND COMPACT. IT IS TO BECOME OF HIM. WORLDLY MAN WHO NOT LONG BE SO IMPROVIDENT IN A SPUNGING HOUSE WHERE THE DEVIATION IS NECESSARY TO KEEP OFF THE SUBJECT. TO MAKE ONE SON. WHY CANNOT I CANNOT SUPPOSE IT POSSIBLE THAT SHE MIGHT THINK NECESSARY FOR ME. TO THE ADVANCED AGE OF BLUSHING. MADE NO RESISTANCE THAT WAS GIVEN AND SIR WALTER COULD MATERIALLY ALTER HIS STYLE OF EQUAL SOLICITUDE ON TOPICS WHICH HAD ALWAYS ADMITTED A HOPE WHILE EDWARD WAS ALLOWED TO STIR AND TRIED TO BE SPARED FROM THE STILES. COTTAGE TO TELL HIM WILL DO EVERYTHING. AND TO OFFER SOME KIND OF A FAR MORE INCURABLE NATURE. DELICACY AND WELL JUDGING A FRIEND OF HIS STAY WAS GRIEVED TO THINK HIS ACQUAINTANCE WITH HIM AFTER KNOWING AS SOONER OR LATER I MUST SAY IT HIMSELF AND THESE WERE THOUGHTS WITH THEIR ATTENDANT VISIONS WHICH OCCUPIED ANNE WHILE THE MUSGROVES ONE OF.\n"
     ]
    }
   ],
   "source": [
    "generate_text('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHE COULD NOT BE DECEIVED IN THAT FLOW OF THE EVENT OF HIS GOOD HUMOURED ACQUIESCENCE. PART BY OUR LONG VERY LONG ABSENCE SINCE WE PARTED IF THAT S ALL. ADAPTED BY RESEMBLANCE OF DISPOSITION. I HAD FULLY INTENDED TO MARRY JAMES BENWICK IS VERY FINE OBJECT FROM MANY PARTS OF THEM. HE IS IN SUCH MOMENTS OF COMMUNICATIONS CONTINUALLY OCCURRING AND ALWAYS THE HOPE OF EXCITING. EXCUSE THE LIBERTY I TAKE IT SO. I OWED TO THEM. SHE WAS SURE THAT HE SOMETIMES TOOK OUT HER HAND WHICH SHE COULD SAY TO HER DAUGHTER. THAT THEY HAD LEFT THE DINING ROOM AND SAID. THINGS ON THE GROUND. HEIGHTENED COLOUR AND AN OFFICER WHOM HE HAD NEVER WITNESSED IN HIM I AM AFRAID THERE HAD BEEN A GOOD EXCUSE AND HE TOLD ME SO BUSY HAVE HAD TO ENQUIRE AFTER MARIANNE WAS IN THE HAPPINESS WHICH MADE HER DAILY COMPLAINT. TO HIS MOTHER IN LAW S CONCERNS COULD NOT HEAR OF OUR ACQUAINTANCE FIRST BEGAN. DO BETWEEN YOU ABOUT BUT NEVER HAD SHE BEEN CONSCIOUS OF NOT MARRYING TILL EVERY THING EQUAL TO ANY OTHER WAY. HAD BEEN ORIGINALLY IMPLIED AGAINST HIM THAT THE DESPERATION WHICH HAD BEEN SOLD SOON AFTER TEA TILL THE DOOR SUSPENDED EVERYTHING. SCENES OF MISERY IN WHICH HER SISTER HAD EXPECTED TO HAVE HER FOR A COUPLE OF.\n"
     ]
    }
   ],
   "source": [
    "generate_text('she')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.to_csv(\"{}/austen-VOCAB.csv\".format(data_out))\n",
    "tokens.to_csv(\"{}/austen-TOKENS.csv\".format(data_out))\n",
    "m1.to_csv(\"{}/austen-M1.csv\".format(data_out))\n",
    "m2.to_csv(\"{}/austen-M2.csv\".format(data_out))\n",
    "m3.to_csv(\"{}/austen-M3.csv\".format(data_out))\n",
    "m2m.to_csv(\"{}/austen-M2M.csv\".format(data_out))\n",
    "m3m.to_csv(\"{}/austen-M3M.csv\".format(data_out))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS5559_LMs.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
